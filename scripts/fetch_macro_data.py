# scripts/fetch_macro_data.py
from __future__ import annotations

from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, Optional, List

import pandas as pd
import yfinance as yf

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data"
CSV_PATH = DATA_DIR / "macro_data.csv"
DATA_DIR.mkdir(parents=True, exist_ok=True)

KST = timezone(timedelta(hours=9))

INDICATORS = {
    "US10Y": "^TNX",      # ë¯¸êµ­ 10ë…„ë¬¼
    "DXY": "DX-Y.NYB",    # ë‹¬ëŸ¬ ì¸ë±ìŠ¤
    "WTI": "CL=F",        # ìœ ê°€
    "VIX": "^VIX",        # ë³€ë™ì„±
    "USDKRW": "KRW=X",    # ì›/ë‹¬ëŸ¬
    "HYG": "HYG",
    "LQD": "LQD",
    

    # âœ… Sector ETFs (Correlation Break / Sector Layerìš©)
    "XLK": "XLK",         # Technology
    "XLF": "XLF",         # Financials
    "XLE": "XLE",         # Energy
    "XLRE": "XLRE",       # Real Estate

    # ğŸ”¥ Growth vs Market Core
    "QQQ": "QQQ",
    "SPY": "SPY",
}

def _safe_last_close(df: pd.DataFrame) -> Optional[float]:
    """yfinance ê²°ê³¼ì—ì„œ ë§ˆì§€ë§‰ closeë¥¼ 'ë¬´ì¡°ê±´ float í•˜ë‚˜'ë¡œ ë½‘ì•„ì˜¤ê¸°(Series/MultiIndex ë°©ì–´)."""
    if df is None or df.empty:
        return None

    # MultiIndex columns (ì˜ˆ: ('Close','^TNX')) í˜•íƒœ ë°©ì–´
    if isinstance(df.columns, pd.MultiIndex):
        close_cols = [c for c in df.columns if str(c[0]).lower() == "close"]
        if not close_cols:
            return None
        close_block = df[close_cols].dropna(how="all")
        if close_block.empty:
            return None
        last_row = close_block.iloc[-1]  # Series (tickerë“¤)
        last_row = last_row.dropna()
        if last_row.empty:
            return None
        return float(last_row.iloc[-1])

    # ì¼ë°˜ ì»¬ëŸ¼
    if "Close" not in df.columns:
        cands = [c for c in df.columns if str(c).lower() == "close"]
        if not cands:
            return None
        close_col = cands[0]
    else:
        close_col = "Close"

    close = df[close_col].dropna()
    if close.empty:
        return None

    last = close.iloc[-1]

    # âœ… lastê°€ Seriesë¡œ ë–¨ì–´ì§€ëŠ” ì¼€ì´ìŠ¤ ë°©ì–´
    if isinstance(last, pd.Series):
        last = last.dropna()
        if last.empty:
            return None
        last = last.iloc[-1]

    return float(last)

def fetch_macro_data() -> Dict[str, float]:
    results: Dict[str, float] = {}

    for name, ticker in INDICATORS.items():
        print(f"Fetching {name} ({ticker}) ...")

        df = yf.download(
            ticker,
            period="7d",
            interval="1d",
            progress=False,
            group_by="column",
            threads=False,
            auto_adjust=False,
        )

        value = _safe_last_close(df)
        if value is None:
            raise RuntimeError(f"[{name}] No valid Close data from yfinance (ticker={ticker}).")

        results[name] = value
        print(f"  â†’ {name}: {value}")

    return results


def append_to_csv(values: Dict[str, float]) -> None:
    now = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")

    # âœ… rowëŠ” ë‘˜ ë‹¤ ì±„ì›Œë‘ì (í˜¸í™˜ì„±)
    row = {"datetime": now, "date": now}
    row.update(values)

    df_row = pd.DataFrame([row])

    file_exists = CSV_PATH.exists()

    if file_exists:
        # âœ… ê¸°ì¡´ í—¤ë”ë¥¼ ì½ì–´ì„œ ê·¸ ìˆœì„œëŒ€ë¡œ ì»¬ëŸ¼ ë§ì¶°ì„œ ì €ì¥ (í•µì‹¬!)
        with open(CSV_PATH, "r", encoding="utf-8") as f:
            header_cols = f.readline().strip().split(",")

        # ì—†ëŠ” ì»¬ëŸ¼ì€ ìƒì„± (NaN)
        for c in header_cols:
            if c not in df_row.columns:
                df_row[c] = pd.NA

        # í—¤ë” ìˆœì„œëŒ€ë¡œ ì¬ì •ë ¬
        df_row = df_row[header_cols]

        # âœ… append
        df_row.to_csv(CSV_PATH, mode="a", index=False, header=False)
    else:
        # âœ… ìƒˆ íŒŒì¼ì´ë©´ ì›í•˜ëŠ” í‘œì¤€ í—¤ë”ë¡œ ìƒì„±
        # (ì—¬ê¸°ì„œëŠ” datetime, US10Y..., date, XLK... í˜•íƒœë¡œ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´ ìˆœì„œ ê°•ì œ ê°€ëŠ¥)
        df_row.to_csv(CSV_PATH, mode="w", index=False, header=True)

    print(f"\nâœ… Saved row to {CSV_PATH}")
    print(df_row)
    
if __name__ == "__main__":
    vals = fetch_macro_data()
    append_to_csv(vals)
