# scripts/fetch_macro_data.py
from __future__ import annotations

from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, Optional, List

import pandas as pd
import yfinance as yf

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data"
CSV_PATH = DATA_DIR / "macro_data.csv"
DATA_DIR.mkdir(parents=True, exist_ok=True)

KST = timezone(timedelta(hours=9))

INDICATORS = {
    "US10Y": "^TNX",      # ë¯¸êµ­ 10ë…„ë¬¼
    "DXY": "DX-Y.NYB",    # ë‹¬ëŸ¬ ì¸ë±ìŠ¤
    "WTI": "CL=F",        # ìœ ê°€
    "VIX": "^VIX",        # ë³€ë™ì„±
    "USDKRW": "KRW=X",    # ì›/ë‹¬ëŸ¬
    "HYG": "HYG",
    "LQD": "LQD",
    

    # âœ… Sector ETFs (Correlation Break / Sector Layerìš©)
    "XLK": "XLK",         # Technology
    "XLF": "XLF",         # Financials
    "XLE": "XLE",         # Energy
    "XLRE": "XLRE",       # Real Estate

    # ğŸ”¥ Growth vs Market Core
    "QQQ": "QQQ",
    "SPY": "SPY",
}

def _safe_last_close(df: pd.DataFrame) -> Optional[float]:
    """yfinance ê²°ê³¼ì—ì„œ ë§ˆì§€ë§‰ closeë¥¼ 'ë¬´ì¡°ê±´ float í•˜ë‚˜'ë¡œ ë½‘ì•„ì˜¤ê¸°(Series/MultiIndex ë°©ì–´)."""
    if df is None or df.empty:
        return None

    # MultiIndex columns (ì˜ˆ: ('Close','^TNX')) í˜•íƒœ ë°©ì–´
    if isinstance(df.columns, pd.MultiIndex):
        close_cols = [c for c in df.columns if str(c[0]).lower() == "close"]
        if not close_cols:
            return None
        close_block = df[close_cols].dropna(how="all")
        if close_block.empty:
            return None
        last_row = close_block.iloc[-1]  # Series (tickerë“¤)
        last_row = last_row.dropna()
        if last_row.empty:
            return None
        return float(last_row.iloc[-1])

    # ì¼ë°˜ ì»¬ëŸ¼
    if "Close" not in df.columns:
        cands = [c for c in df.columns if str(c).lower() == "close"]
        if not cands:
            return None
        close_col = cands[0]
    else:
        close_col = "Close"

    close = df[close_col].dropna()
    if close.empty:
        return None

    last = close.iloc[-1]

    # âœ… lastê°€ Seriesë¡œ ë–¨ì–´ì§€ëŠ” ì¼€ì´ìŠ¤ ë°©ì–´
    if isinstance(last, pd.Series):
        last = last.dropna()
        if last.empty:
            return None
        last = last.iloc[-1]

    return float(last)

def fetch_macro_data() -> Dict[str, float]:
    results: Dict[str, float] = {}

    for name, ticker in INDICATORS.items():
        print(f"Fetching {name} ({ticker}) ...")

        df = yf.download(
            ticker,
            period="7d",
            interval="1d",
            progress=False,
            group_by="column",
            threads=False,
            auto_adjust=False,
        )

        value = _safe_last_close(df)
        if value is None:
            raise RuntimeError(f"[{name}] No valid Close data from yfinance (ticker={ticker}).")

        results[name] = value
        print(f"  â†’ {name}: {value}")

    return results


def append_to_csv(values: Dict[str, float]) -> None:
    now = datetime.now(KST).strftime("%Y-%m-%d %H:%M:%S")

    # 1) ìƒˆ row ë§Œë“¤ê¸°
    row = {"date": now}
    row.update(values)
    df_row = pd.DataFrame([row])

    # 2) íŒŒì¼ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ìƒˆë¡œ ìƒì„±
    if not CSV_PATH.exists():
        df_row.to_csv(CSV_PATH, index=False)
        print(f"\nâœ… Created new CSV: {CSV_PATH}")
        print(df_row)
        return

    # 3) âœ… íŒŒì¼ì´ ì´ë¯¸ ìˆìœ¼ë©´: í—¤ë”ì— ìƒˆ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
    existing = pd.read_csv(CSV_PATH, nrows=0)
    existing_cols = list(existing.columns)

    # ìš°ë¦¬ê°€ ë„£ê³  ì‹¶ì€ ì „ì²´ ì»¬ëŸ¼ = (ê¸°ì¡´ + ìƒˆ row ì»¬ëŸ¼)
    desired_cols = list(dict.fromkeys(existing_cols + list(df_row.columns)))

    # âœ… ê¸°ì¡´ í—¤ë”ì— ì—†ëŠ” ì»¬ëŸ¼ì´ ìƒê²¼ë‹¤ë©´: ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜(ë°±ì—… + rewrite)
    missing_in_file = [c for c in df_row.columns if c not in existing_cols]
    if missing_in_file:
        backup_path = CSV_PATH.with_suffix(".csv.bak")
        CSV_PATH.replace(backup_path)  # ì›ë³¸ ë°±ì—…(ì´ë™)

        # ë°±ì—… íŒŒì¼ ë¡œë“œ â†’ ì»¬ëŸ¼ í™•ì¥ â†’ ë‹¤ì‹œ ì €ì¥
        old_df = pd.read_csv(backup_path)
        for c in desired_cols:
            if c not in old_df.columns:
                old_df[c] = pd.NA

        # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬ (ê¸°ì¡´ ì»¬ëŸ¼ ìœ ì§€ + ë’¤ì— ìƒˆ ì»¬ëŸ¼)
        old_df = old_df[desired_cols]
        old_df.to_csv(CSV_PATH, index=False)
        print(f"[OK] macro_data.csv schema upgraded. backup -> {backup_path}")
        print(f"[OK] added columns: {missing_in_file}")

        # ê¸°ì¡´ í—¤ë” ìƒˆë¡œ ì½ê¸°
        existing_cols = desired_cols

    # 4) âœ… append (í•­ìƒ CSV í—¤ë” ì»¬ëŸ¼ ìˆœì„œì— ë§ì¶°ì„œ ì €ì¥)
    # íŒŒì¼ ì»¬ëŸ¼ì— ì—†ëŠ” í‚¤ëŠ” ë¬´ì‹œë˜ì§€ ì•Šë„ë¡, ì—†ìœ¼ë©´ NaNìœ¼ë¡œ ì±„ì›€
    for c in existing_cols:
        if c not in df_row.columns:
            df_row[c] = pd.NA
    df_row = df_row[existing_cols]

    df_row.to_csv(CSV_PATH, mode="a", index=False, header=False)

    print(f"\nâœ… Appended row to {CSV_PATH}")
    print(df_row)
    
if __name__ == "__main__":
    vals = fetch_macro_data()
    append_to_csv(vals)
